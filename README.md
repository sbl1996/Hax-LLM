![Hax-LLM Logo](/docs/_static/hax-llm-2.jpg)

--------------------------------------------------------------------------------

`Hax-LLM` is Hastur's experiments in scaling LLM to 10B+ parameters with JAX and TPUs.

## Experiments
Check the experiments and training scripts on this [repo](https://github.com/sbl1996/llm_experiments).

## Sponsors
This work is supported with Cloud TPUs from Google's [TPU Research Cloud (TRC)](https://sites.research.google/trc/about/).

## Logo
The logo of `Hax-LLM` is designed by Adobe Firefly. Amazing!